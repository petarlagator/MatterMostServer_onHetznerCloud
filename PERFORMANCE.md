# Performance Testing Results

> **Disclaimer**: These are synthetic load test results using [Locust](https://locust.io). Tests simulate concurrent users posting messages and uploading files. Real-world performance varies significantly based on actual usage patterns, installed plugins, file sizes, database queries, and concurrent active users vs. registered users. Your mileage may vary.

## Executive Summary

**üèÜ ULTIMATE FINDING**: **CPX32 (4 AMD EPYC cores) is the ABSOLUTE CHAMPION!** Handles 1250 users with 35ms median response time and near-zero failures. At 1500 users, still maintains 35ms median with only 0.42% failure rate. Best performance-per-euro winner!

### Quick Recommendations

| Your Scale | Best Instance | Price | Capacity | Why |
|------------|--------------|-------|----------|-----|
| **0-400 users** | **CX23** | ‚Ç¨3/mo | 400 users | Cheapest, good enough |
| **400-750 users** | **CPX22** | ‚Ç¨6/mo | 750 users | Best value, fastest at this scale |
| **750-1000 users** | **CX33** | ‚Ç¨5/mo | 1000 users | More cores, great value |
| **1000-1500+ users** | **CPX32** | **‚Ç¨10.50/mo** | **1500+ users** | **Unbeatable performance!** |

**The Big Revelation**: 4 AMD EPYC cores (CPX32) = ULTIMATE WINNER. Combines AMD's single-thread speed with 4-core parallelization. Worth every cent for 1000+ users!

## Testing Methodology

### Test Setup

- **Tool**: Locust load testing framework (Python-based)
- **Test Location**: Separate Hetzner Cloud instance (to simulate real network conditions)
- **Test Pattern**: 
  - Each simulated user sends **1 message every ~5 seconds**
  - Each simulated user uploads **1 file (~100 bytes text file) every ~2 minutes**
  - Users ramped up gradually (25-30 users/second depending on test scale)
  - Tests run 10 minutes per load level

### Server Configuration

- **Deployment**: Standard Docker setup from this repository
- **Stack**: Mattermost + PostgreSQL + NGINX (all containerized)
- **Network**: Cloudflare proxy in front (with IP whitelisting for test traffic)
- **Authentication**: Bot token used for API requests
- **No customizations**: Default configuration, no performance tuning applied

### Metrics Explained

- **Concurrent Users**: Number of users actively sending messages simultaneously
  - This is NOT total registered users
  - Real-world ratio: typically 5-20% of registered users are concurrently active
  - Example: 200 concurrent active users ‚âà 1,000-4,000 total registered users

- **Throughput**: Total requests per second (messages + file uploads)

- **Response Times**:
  - **Median (50th percentile)**: Typical user experience
  - **95th percentile**: 95% of requests faster than this
  - **99th percentile**: Worst-case for 99% of requests
  - Response time = time from request sent to response received

- **CPU Percentage**: Can exceed 100% on multi-core systems
  - 200% = 2 vCPU cores fully utilized
  - Shows as load average in system metrics

## Test Results

### üèÜ Hetzner CPX32 (4 vCPU AMD EPYC, 8GB RAM, ‚Ç¨10.50/month) - **CHAMPION!**

**Server Specs**: AMD EPYC (Milan), 4 shared vCPU cores, 8GB RAM, 160GB SSD

| Concurrent Users | Throughput (req/s) | Median Response | 95th Percentile | 99th Percentile | Failure Rate | CPU Idle | Load Avg | Notes |
|-----------------|-------------------|-----------------|-----------------|-----------------|--------------|----------|----------|-------|
| 1250 | 290 | **35ms** | **190ms** | **440ms** | **0.07%** | **24%** | 8.0 | ‚úÖ **CRUSHING IT!** - Still has headroom |
| 1500 | 305 | **35ms** | **340ms** | **980ms** | **0.42%** | **33%** | 7.9 | ‚úÖ **INCREDIBLE!** - 99.58% success rate |

#### CPX32 Analysis - THE ULTIMATE WINNER üéâ

**Recommended Capacity**:
- **Comfortable**: Up to 1500 concurrent active users with **sub-40ms response times**
- **Maximum**: Likely 1750-2000 concurrent users before degradation
- **Sweet Spot**: 1250 users = 35ms median, 0.07% failures, 24% CPU idle

**Real-World Translation**:
- Very large team: 5,000-15,000 registered users ‚Üí CPX32 is perfect
- Enterprise: 15,000-30,000 registered users ‚Üí CPX32 handles excellently
- Massive scale: 30,000+ registered users ‚Üí CPX32 still has headroom!

**Performance vs ALL Others @ 1250 users**:

**vs CPX22 (2 AMD EPYC cores):**
- **93% faster median** (35ms vs 470ms!)
- **91% better 95th percentile** (190ms vs 2200ms!)
- **86% better 99th percentile** (440ms vs 3100ms!)
- **98% fewer failures** (0.07% vs 4.5%)

**vs CX33 (4 Intel cores):**
- **96% faster median** (35ms vs 1000ms!)
- **94% better 95th percentile** (190ms vs 3100ms!)
- **90% better 99th percentile** (440ms vs 4200ms!)
- **99% fewer failures** (0.07% vs 6.0%)

**vs CCX13 (2 AMD EPYC dedicated):**
- **96% faster median** (35ms vs 930ms!)
- **94% better 95th percentile** (190ms vs 3100ms!)
- **94% better 99th percentile** (440ms vs 7100ms!)
- **99% fewer failures** (0.07% vs 6.7%)

**At 1500 Users - Still Dominating:**
- Processed **56,370 requests** with **99.58% success rate**
- Maintained **35ms median** throughout entire test
- **95% of requests** completed in under 340ms
- **99% of requests** completed in under 980ms
- Still had **33% CPU idle** - room for more!

**Bottleneck**: None observed yet! At 1500 users still has 33% CPU headroom. The 4 AMD EPYC cores provide both **fast single-thread performance** AND **excellent parallelization** for PostgreSQL.

**Key Observations**:
- **4 AMD EPYC cores = BEST OF BOTH WORLDS**: Fast per-core like CPX22 + parallelization like CX33
- Maintains **identical 35ms median** at both 1250 AND 1500 users
- **Only ‚Ç¨4.50/month more than CX33** but DRAMATICALLY better worst-case performance
- 99th percentile at 1500 users (980ms) is still better than CX33's median at 1250 users (1000ms)!
- **Worth EVERY cent** for production workloads over 1000 users

**Cost per 100 Users**: ‚Ç¨0.70 at 1500 capacity (very competitive!)

---

### Hetzner CX23 (2 vCPU Intel, 4GB RAM, ‚Ç¨3/month)

**Server Specs**: Intel Xeon, 2 shared vCPU cores, 4GB RAM, 40GB SSD

| Concurrent Users | Throughput (req/s) | Median Response | 95th Percentile | 99th Percentile | Max Response | Failure Rate | CPU Usage | Load Avg | Notes |
|-----------------|-------------------|-----------------|-----------------|-----------------|--------------|--------------|-----------|----------|-------|
| 50 | 10 | 39ms | 60ms | 80ms | 98ms | 0% | ~15% | 0.3 | ‚úÖ **Excellent** - Plenty of headroom |
| 200 | 40 | 47ms | 100ms | 150ms | 200ms | 0% | ~85% | 1.8 | ‚úÖ **Good** - Responsive, CPU getting busy |
| 400 | 80 | 46ms | 150ms | 300ms | 372ms | 0% | ~130% | 3.2 | ‚ö†Ô∏è **Acceptable** - CPU maxed, occasional spikes |
| 500 | 100 | 46ms | 200ms | 2000ms | 1677ms | 0% | ~140% | 4.5 | ‚ö†Ô∏è **Borderline** - Noticeable worst-case delays |
| 750 | 115 | **1000ms** | 3400ms | 4700ms | 9174ms | 0% | ~160% | 8.3 | ‚ùå **Poor UX** - 1 second lag, users notice |

#### CX23 Analysis

**Recommended Capacity**:
- **Comfortable**: 200-300 concurrent active users for excellent performance (sub-50ms)
- **Maximum**: 400 concurrent users with acceptable degradation
- **Do not exceed**: 600+ users (response times exceed 1 second)

**Real-World Translation**:
- Small team: 50-100 registered users ‚Üí CX23 is perfect
- Medium team: 500-2,000 registered users ‚Üí CX23 works well
- Large team: 2,000+ registered users ‚Üí Consider CPX22 or higher

**Bottleneck**: CPU becomes saturated at 400+ users. Memory usage remained comfortable (<1GB) throughout all tests.

---

### Hetzner CPX22 (2 vCPU AMD EPYC, 4GB RAM, ‚Ç¨6/month)

**Server Specs**: AMD EPYC (Milan), 2 shared vCPU cores, 4GB RAM, 80GB SSD

| Concurrent Users | Throughput (req/s) | Median Response | 95th Percentile | 99th Percentile | Failure Rate | CPU Usage | Load Avg | Notes |
|-----------------|-------------------|-----------------|-----------------|-----------------|--------------|-----------|----------|-------|
| 400 | 82 | 34ms | 110ms | 180ms | 0% | ~100% | 0.9 | ‚úÖ **Excellent** - Much better than CX23 |
| 750 | 155 | **35ms** | 160ms | 240ms | 0% | ~150% | 4.7 | ‚úÖ **Excellent** - Still responsive |
| 1250 | 240 | 470ms | 2200ms | 3100ms | 4.5% | ~180% | 14.7 | ‚ùå **Breaking point** - Errors start |
| 1500 | 247 | 660ms | 2500ms | 4500ms | 5.6% | ~190% | 16.8 | ‚ùå **Failed** - High error rate |

#### CPX22 Analysis

**Recommended Capacity**:
- **Comfortable**: Up to 750 concurrent active users with excellent sub-40ms response times
- **Maximum**: 1000 concurrent users with some degradation
- **Breaking point**: 1250+ users (errors and >400ms median)

**Real-World Translation**:
- Medium team: 1,000-3,000 registered users ‚Üí CPX22 is excellent
- Large team: 3,000-7,500 registered users ‚Üí CPX22 handles well
- Very large: 10,000+ registered users ‚Üí Consider CX33 or CPX32

**Performance vs CX23**:
- **88% more concurrent users** (750 vs 400) at comfortable performance levels
- **26% faster median response** at 400 users (34ms vs 46ms)
- **40% faster 99th percentile** at 400 users (180ms vs 300ms)
- **Only 100% more expensive** (‚Ç¨6 vs ‚Ç¨3/month) - still excellent value!

---

### Hetzner CCX13 (2 vCPU AMD EPYC Dedicated, 8GB RAM, ‚Ç¨12/month)

**Server Specs**: AMD EPYC (Milan), 2 **dedicated** vCPU cores, 8GB RAM, 80GB SSD

| Concurrent Users | Throughput (req/s) | Median Response | 95th Percentile | 99th Percentile | Failure Rate | CPU Usage | Load Avg | Notes |
|-----------------|-------------------|-----------------|-----------------|-----------------|--------------|-----------|----------|-------|
| 750 | 120 | **33ms** | 200ms | 320ms | 0% | ~60% | 4.1 | ‚úÖ **Perfect** - 35% CPU idle |
| 1000 | 157 | 51ms | 1600ms | 2700ms | 1.90% | ~77% | 6.5 | ‚ö†Ô∏è **Degrading** - Starting to fail |
| 1250 | 178 | 930ms | 3100ms | 7100ms | 6.73% | ~200% | 14.0 | ‚ùå **Failed** - High error rate |

#### CCX13 Analysis

**Recommended Capacity**:
- **Comfortable**: Up to 900 concurrent active users with excellent sub-50ms response times
- **Maximum**: 1000 concurrent users with minor degradation
- **Breaking point**: 1250+ users (errors and >900ms median)

**Key Observations**:
- Dedicated cores don't provide massive performance gains at comfortable load levels
- Main benefit: **guaranteed performance** - no CPU sharing with other tenants
- At 750 users, CCX13 has 35% CPU idle (headroom for traffic spikes)
- Only worth the 100% premium over CPX22 if you need **predictable, consistent performance**

---

### Hetzner CX33 (4 vCPU Intel, 8GB RAM, ‚Ç¨5/month)

**Server Specs**: Intel Xeon, 4 shared vCPU cores, 8GB RAM, 80GB SSD

| Concurrent Users | Throughput (req/s) | Median Response | 95th Percentile | 99th Percentile | Failure Rate | CPU Usage | Load Avg | Notes |
|-----------------|-------------------|-----------------|-----------------|-----------------|--------------|-----------|----------|-------|
| 750 | 154 | 38ms | 160ms | 240ms | 0.07% | ~63% | 4.0 | ‚úÖ **Excellent** - 37% CPU idle |
| 1000 | 159 | **46ms** | **210ms** | **520ms** | **0.07%** | ~73% | 8.8 | ‚úÖ **Excellent** - 27% CPU idle |
| 1250 | 189 | **1000ms** | 3100ms | 4200ms | 6.0% | ~41% | 20.3 | ‚ùå **Failed** - Breaking point |

#### CX33 Analysis

**Recommended Capacity**:
- **Comfortable**: Up to 1000 concurrent active users with excellent sub-50ms response times
- **Maximum**: 1000-1100 concurrent users before significant degradation
- **Breaking point**: 1250+ users (errors and >1000ms median)

**Performance vs CPX22 @ 1000 users**:
- **10% faster median** (46ms vs 51ms)
- **87% better 95th percentile** (210ms vs 1600ms!)
- **81% better 99th percentile** (520ms vs 2700ms!)
- **96% fewer failures** (0.07% vs 1.90%)
- **17% cheaper** (‚Ç¨5 vs ‚Ç¨6/month)

**Key Observations**:
- **4 Intel cores beat 2 AMD EPYC cores** at high concurrent load (1000+ users)
- PostgreSQL benefits massively from multiple cores for query parallelization
- Best price/performance for 1000 concurrent users
- However, CPX32 (4 AMD cores) absolutely crushes it at ‚Ç¨10.50/month

---

## üìä All Instances @ 1250 Users - THE ULTIMATE COMPARISON

| Instance | CPU Type | Cores | Price | Median | 95%ile | 99%ile | Failures | CPU Idle | Winner? |
|----------|----------|-------|-------|--------|--------|--------|----------|----------|---------|
| **CPX22** | AMD EPYC | 2 | ‚Ç¨6 | 470ms | 2200ms | 3100ms | **4.5%** | 23% | ‚ùå Failed |
| **CCX13** | AMD EPYC (ded) | 2 | ‚Ç¨12 | 930ms | 3100ms | 7100ms | **6.7%** | 0% | ‚ùå Failed |
| **CX33** | Intel | 4 | ‚Ç¨5 | 1000ms | 3100ms | 4200ms | **6.0%** | 59% | ‚ùå Failed |
| **CPX32** | AMD EPYC | 4 | **‚Ç¨10.50** | **35ms** | **190ms** | **440ms** | **0.07%** | **24%** | ‚úÖ **CHAMPION** |

**CPX32 is 93-96% faster and has 98-99% fewer failures than all competitors!**

---

## üìä COMPLETE PERFORMANCE MATRIX

### Best Instance by User Count

| User Range | Champion | Price | Median | Why |
|------------|----------|-------|--------|-----|
| **0-400** | **CX23** | ‚Ç¨3 | 46ms | Cheapest, good enough |
| **400-750** | **CPX22** | ‚Ç¨6 | **35ms** | Best value, fastest at this scale |
| **750-1000** | **CX33** | ‚Ç¨5 | 46ms | More cores, great value |
| **1000-1500+** | **CPX32** | **‚Ç¨10.50** | **35ms** | **Unbeatable performance!** |

### Value Analysis (Cost per 100 Users @ Peak)

| Instance | Peak Capacity | Price | Cost per 100 Users | Value Rating |
|----------|---------------|-------|-------------------|--------------|
| CX23 | 400 | ‚Ç¨3.00 | ‚Ç¨0.75 | ‚≠ê‚≠ê‚≠ê |
| CPX22 | 750 | ‚Ç¨6.00 | ‚Ç¨0.80 | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Best Budget |
| CX33 | 1000 | ‚Ç¨5.00 | **‚Ç¨0.50** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Best Value |
| CCX13 | 900 | ‚Ç¨12.00 | ‚Ç¨1.33 | ‚≠ê‚≠ê‚≠ê Premium |
| **CPX32** | **1500+** | **‚Ç¨10.50** | **‚Ç¨0.70** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê **Best Performance** |

---

## üéØ THE BIG REVELATION

### CPX32 Proves: **4 AMD EPYC cores = ULTIMATE WINNER**

**Why CPX32 dominates:**

1. **AMD EPYC single-thread performance** (fast per-core like CPX22)
2. **4 cores for parallelization** (like CX33 but with faster cores)
3. **Best of both worlds!**

**Performance vs CX33 @ 1250 users:**
- **96% faster median** (35ms vs 1000ms!)
- **94% better 95th percentile** (190ms vs 3100ms!)
- **90% better 99th percentile** (440ms vs 4200ms!)
- **99% fewer failures** (0.07% vs 6.0%)

**Performance vs CPX22 @ 1250 users:**
- **93% faster median** (35ms vs 470ms!)
- **91% better 95th percentile** (190ms vs 2200ms!)
- **86% better 99th percentile** (440ms vs 3100ms!)
- **98% fewer failures** (0.07% vs 4.5%)

---

## üí° FINAL RECOMMENDATIONS

### Budget Recommendation:
- **Up to 750 users**: **CPX22** (‚Ç¨6/month) - unbeatable value
- **750-1000 users**: **CX33** (‚Ç¨5/month) - best bang for buck

### Performance Recommendation:
- **1000+ users**: **CPX32** (‚Ç¨10.50/month) - worth EVERY cent!
- Still has **24-33% CPU headroom** at 1250-1500 users
- Likely handles **1750-2000 users** comfortably

### Enterprise Recommendation:
- **CPX32** is the clear choice for production workloads
- Only **‚Ç¨5.50/month** more than CX33
- **Dramatically** better worst-case performance (99th percentile)
- Nearly zero failures even under extreme load

---

## Performance Optimization Tips

### Without Upgrading Hardware

1. **Enable PostgreSQL connection pooling** - Reduces database overhead
2. **Disable unused plugins** - Saves CPU cycles
3. **Tune PostgreSQL** - Adjust `shared_buffers` and `work_mem`
4. **Use object storage for files** - Offload file serving to S3-compatible storage
5. **Enable Elasticsearch** (if needed) - Offload search from PostgreSQL

### When to Upgrade

- **CPU consistently >80%**: Upgrade to more vCPUs
- **Memory >3.5GB**: Upgrade RAM
- **Response times >100ms median**: Consider horizontal scaling
- **Need guaranteed performance**: Switch to dedicated (CCX) cores
- **>1500 concurrent users**: Consider CPX42 (8 AMD EPYC cores) or horizontal scaling

---

## Running Your Own Tests

### Quick Test Setup

Use this cloud-init script to spin up a load tester on Hetzner:

```yaml
#cloud-config
packages:
  - python3
  - python3-pip
  - python3-venv

write_files:
  - path: /root/locustfile.py
    content: |
      import os
      import random
      import string
      from locust import HttpUser, task, between
      from io import BytesIO

      # Configuration
      MATTERMOST_URL = "https://your-server.com"
      BOT_TOKEN = "your-bot-token"
      CHANNEL_ID = "your-channel-id"

      class MattermostUser(HttpUser):
          wait_time = between(4, 6)
          
          def on_start(self):
              self.client.headers.update({
                  "Authorization": f"Bearer {BOT_TOKEN}",
                  "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
              })
              self.file_counter = 0
          
          @task(24)
          def post_message(self):
              message_text = f"Test message: {self.random_text(10)}"
              payload = {"channel_id": CHANNEL_ID, "message": message_text}
              self.client.post("/api/v4/posts", json=payload)
          
          @task(1)
          def upload_file(self):
              self.file_counter += 1
              file_content = f"Test file {self.file_counter}\n{self.random_text(100)}"
              file_data = BytesIO(file_content.encode())
              files = {'files': (f'test_{self.file_counter}.txt', file_data, 'text/plain')}
              
              response = self.client.post(f"/api/v4/files?channel_id={CHANNEL_ID}", files=files)
              if response.status_code == 201:
                  file_id = response.json()['file_infos'][0]['id']
                  self.client.post("/api/v4/posts", json={
                      "channel_id": CHANNEL_ID,
                      "message": f"File upload test {self.file_counter}",
                      "file_ids": [file_id]
                  })
          
          @staticmethod
          def random_text(length):
              return ''.join(random.choices(string.ascii_letters + string.digits + ' ', k=length))

  - path: /root/start_test.sh
    permissions: '0755'
    content: |
      #!/bin/bash
      sleep 10
      python3 -m venv /root/locust-venv
      source /root/locust-venv/bin/activate
      pip install --upgrade pip
      pip install locust
      
      cd /root
      locust -f locustfile.py \
        --headless \
        --users 200 \
        --spawn-rate 10 \
        --host "https://your-server.com" \
        --run-time 30m \
        --html /root/locust_report.html \
        --csv /root/locust_stats

runcmd:
  - /root/start_test.sh > /root/locust.log 2>&1 &
```

### Prerequisites for Testing

1. **Create a bot account** in Mattermost (System Console ‚Üí Integrations ‚Üí Bot Accounts)
2. **Get bot token** and channel ID
3. **Whitelist test server IP** in Cloudflare (to avoid bot protection blocking)
4. **Update cloud-init**: Replace `MATTERMOST_URL`, `BOT_TOKEN`, and `CHANNEL_ID`
5. **Spin up Hetzner instance** with the cloud-init script
6. **Monitor**: SSH in and run `tail -f /root/locust.log`

---

## Comparison with Other Hosting Options

### Why Hetzner Cloud?

| Provider | Instance | vCPU | RAM | Price/month | CPX32 Equivalent |
|----------|----------|------|-----|-------------|------------------|
| Hetzner | CPX32 | 4 | 8GB | ‚Ç¨10.50 | Baseline |
| AWS | t3.xlarge | 4 | 16GB | ~$120 | 11.4x more expensive |
| DigitalOcean | Basic 8GB | 4 | 8GB | $48 | 4.6x more expensive |
| Azure | B4ms | 4 | 16GB | ~$120 | 11.4x more expensive |

**Verdict**: Hetzner offers exceptional price/performance for European workloads. For 1500 concurrent users, you'd pay $48-120/month on other clouds vs ‚Ç¨10.50 on Hetzner.

---

## Contributions

If you run performance tests on different instance types or configurations, please submit a PR with your results! Include:
- Instance specs
- Test methodology
- Raw Locust output or HTML report
- Any custom configuration changes

---

## Related Documentation

- [Mattermost Scaling Guide](https://docs.mattermost.com/scale/scale-to-high-availability.html)
- [PostgreSQL Tuning](https://wiki.postgresql.org/wiki/Tuning_Your_PostgreSQL_Server)
- [Locust Documentation](https://docs.locust.io/)

---

**Last Updated**: January 19, 2026  
**Mattermost Version**: 11.3.0  
**Test Framework**: Locust 2.43.1  
**Key Finding**: **CPX32 (4 AMD EPYC cores) is the ultimate champion!** Handles 1500 concurrent users with 35ms median response and 99.58% success rate. The perfect combination of single-thread speed and multi-core parallelization.